<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>Compression | Blog</title><meta name="description" content="Compression - Mathijs Henquet"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/theme.css"><link rel="search" type="application/opensearchdescription+xml" href="/atom.xml" title="Blog"></head><body><div class="wrap"><header><h1 class="branding"><a href="/" title="Blog">Blog</a></h1><ul class="nav nav-list"><li class="nav-list-item"><a class="nav-list-link" href="/" target="_self">HOME</a></li><li class="nav-list-item"><a class="nav-list-link" href="https://github.com/mathijshenquet" target="_blank">GITHUB</a></li><li class="nav-list-item"><a class="nav-list-link" href="/atom.xml" target="_self">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Compression</h1><div class="post-info"><a></a>2017-08-15</div><div class="post-content"><p>Any definition of conscience, and therefore intelligence, should somehow incorporate the amount of compression that the agent applies to its senses. In a way compression is the same as understanding in the following way. Suppose we have a sequence of data points, for example the sequence of even numbers. A priori this contains an infinite amount of information, which is impossible to store. But by employing patterns in the data, we can make a finite representation: informally “start at 0 and keep on adding +2”. </p>
<p>Depending on the expressive strength of the agents internal language we can build representations of more complex data[^1]. Depending on the reasoning capacity the agent can then find and exploit more and more patterns in the data allowing for efficient representation.</p>
<p>In practice an agent might be supplied some initial segment of a sequence, i.e. the observations of the first 100 even numbers. Using some form of (probabilistic[^2]) reasoning the agent builds an efficient representation as the informal sentence above. But not only is the data compressed by this, the agent also gains predictive power over future elements of the sequence. </p>
<p>This analogy between compression and understanding cuts both ways. For example by recognizing the depicted objects on a painting, I am at the same time also compressing my internal representation of the painting.</p>
<p>[^1]: The upper bound on the expressive strength, assuming that brains are essentially Turing machines, is storing a representation in some sentence of a Turing complete language.</p>
<p>[^2]: Of course the agent will associate some form of probability that this representation is correct.</p>
</div></article></div></main><footer><div class="paginator"><a class="prev" href="/2017/08/15/rules/">prev</a></div><div class="copyright"><p>&copy; 2016 - 2017 <a href="http://mathijshenquet.github.io">Mathijs Henquet</a>.<br>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/Dreyer/hexo-theme-artemis" target="_blank">Artemis</a>.</p></div></footer></div><script>var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-12345678-9']);
_gaq.push(['_trackPageview']);

(function () {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();</script></body></html>